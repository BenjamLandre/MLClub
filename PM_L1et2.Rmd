---
title: "Elasticnet penalized regression"
output: html_document
references:
- id: jstatsoft_glmnet
  title: Regularization Paths for Generalized Linear Models via Coordinate Descent
  author:
  - family: Friedman, Hastie, Tibshirani
  volume: 11
  URL: 'http://dx.doi.org/10.18637/jss.v033.i01'
  DOI: 10.18637/jss.v033.i01
  issue: 1
  publisher: Nature Publishing Group
  type: article-journal
  issued:
    year: 2010
    month: 2
csl: ieee.csl
---
<style>
  h4{font-size: 35px !important;
    color: #000000 !important;
    border-style: solid;
    border-color: #000000;
    background-color: #FFFFFF;
    text-align: center;
    margin-top: 5px;
  }
</style>  
<style>
  h2{font-size: 35px !important;
    color: #d62d20 !important;
    background-color: #FFFFFF;
    text-align: center;
    margin-top: 5px;
  }
</style>

<h4> Summary of the method </h4>    

Elasticnet models can apply both L1 and L2 regularization to achieve a sparse solution. [@jstatsoft_glmnet]   
<br>
The elasticnet penalty can be modelled as:    

$\lambda$ $\sum_{j = 1}^{p}$[$\frac{1}{2}$(1 - $\alpha$) * $\beta_{j}^{2}$ + $\alpha$ |$\beta_{j}$|]   

Where $\lambda$ represent the regularization parameter, $\alpha$ the mixing percentage between L1 and L2 regularization and $\beta_{j}$ the regression coefficient associated to the j^th^ variable.

The $\alpha$ parameter allows to apply a $\lambda$ weighting using L1 & L2 regularization.
<br>

More comprehensive details can be found [HERE](https://www.jstatsoft.org/article/view/v033i01).       
   
<h4> Code </h4>   
Elasticnet methods is divided on 3 steps:    
<br>
**(1)**   A data management step where variables are scaled, so that a selection between comparable coefficient can be operated, and representative training and validation datasets are defined.     
<br>
**(2)**   A training step where the optimal combination of $\lambda$ and $\alpha$ is defined.   
The optimal $\lambda$ and $\alpha$ combination shows the best predictive performance among several combinations. Predictive performance are calculated using a sampling procedure. The sampling procedure allows to define $\beta$ coefficients in a subset of the data and define its predictive performance on another subset of the data.  
<br>
**(3)**   A validation step where the performance of the model using the optimal $\lambda$ and $\alpha$ combination is calculated on new data that were not involved in the training step.

The rationale for choosing a scaling procedure, the predictive performance metric, what can be considered as optimal, between sampling methodologies and weighting are developed [HERE](https://benjamlandre.github.io/MLClub/), [HERE](https://benjamlandre.github.io/MLClub/), [HERE](https://benjamlandre.github.io/MLClub/), [HERE](https://benjamlandre.github.io/MLClub/) and [HERE](https://benjamlandre.github.io/MLClub/), respectively.   

The code below shows methodologies to select the $\lambda$ and $\alpha$ combination, with the best predictive performances for common metrics, with 2 different un-weighted sampling methodologies (cross-validation, repeated cross-validation) and for 3 different types of outcomes (binary, continuous, time-to-event).         
<br>
Code uses the Heart Failure Prediction data.Information about the dataset can be found in this website ([HERE](https://benjamlandre.github.io/MLClub/index.html)) or on the kaggle site ([HERE](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data?select=heart_failure_clinical_records_dataset.csv)). 

***  

###  
<h2>Cross-validated Elasticnet model</h2>

### {.tabset .tabset-fade .tabset-pills}      

#### Y is binary  

**Summary of the different steps**  
**(1)**    <span style="color:#d62d20">Data management</span>    
Continuous data should be scaled    
Dummy variables must be created for categorical variables   
Training and testing data sets must be created   
  
**(2)**    <span style="color:#d62d20">Training of the data set</span>    
Find $\lambda$ and $\alpha$ which minimize cross-validation measure (deviance for binary outcomes)    
Predict on training dataset using the optimal $\lambda$ and $\alpha$ combination   
  
**(3)**    <span style="color:#d62d20">Predicting on testing data set</span>    
Predict on testing dataset       
  
***

**(1) Data management**  

**Parameters to consider**    
- Scaling methodology [LINK](https://www.google.fr).    
- Weighting of the sampling [LINK](https://www.google.fr).    

The Heart Failure Prediction data was used. The outcome was death at the end of the follow-up and predictors were all others variables.
More information about the dataset can be found in the dataset tab ([HERE](https://WWW.google.fr)) or on the kaggle site ([HERE](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data?select=heart_failure_clinical_records_dataset.csv)).

```{r, message = FALSE}
library(readr)
library(caret)

heart <- as.data.frame(read_csv("heart_failure_clinical_records_dataset.csv", 
                                col_types = cols(DEATH_EVENT = col_factor(levels = c("0", "1")),
                                                 anaemia = col_factor(levels = c("0", "1")),
                                                 sex = col_factor(levels = c("0", "1")),
                                                 smoking = col_factor(levels = c("0", "1")),
                                                 diabetes = col_factor(levels = c("0", "1")),
                                                 high_blood_pressure = col_factor(levels = c("0","1")))))

# Data management of continous variables ----------------------------------------------------

# I) Log transformation for: creatinine_phosphokinase & serum_creatinine
heart$CP_log <- log(heart$creatinine_phosphokinase)
heart$SC_log <- log(heart$serum_creatinine)

# II) Scaling using population summary statistics
Cols <- names(heart[, c(1, 5, 7, 9, 14, 15)])
heart[Cols] <- lapply(heart[Cols], scale)

# III) Remove unused variables
heart <- heart[,-c(3, 8, 12)]

# Sampling ----------------------------------------------------------------------------------

# I) Unweighted sampling
set.seed(11)
trainIndex <- createDataPartition(heart$DEATH_EVENT, p = .7, 
                                  list = FALSE, 
                                  times = 1)
heart_train <- heart[trainIndex,]
heart_test  <- heart[-trainIndex,]

# Data management of categorical variables --------------------------------------------------

# I) Create dummy variables

# II) Separate outcome and predictors in different dataset
x_train <- heart_train[,-c(10)]
x_test <- heart_test[,-c(10)]

y_train <- heart_train$DEATH_EVENT
y_test <- heart_test$DEATH_EVENT

# Data management of categorical variables --------------------------------------------------

# I) Create dummy variables
x_train_dm <- model.matrix( ~ .-1, data = x_train, contrasts.arg = lapply(x_train[,c(2, 3, 5, 8, 9)], contrasts, contrasts=FALSE))
x_test_dm <-  model.matrix( ~ .-1, data = x_test, contrasts.arg = lapply(x_test[,c(2, 3, 5, 8, 9)], contrasts, contrasts=FALSE))
```

***   

**(2) Training of the data set** 

**Parameters to consider**    
-   nfolds: the number of cross-validation (default = 10).    
-   standardize: standardize the x variables (default = TRUE).        
-   $\alpha$: the mixing parameter.    
-   $\lambda$: the choice of optimal $\lambda$ to choose (minimal or in 1SE range of the minimal $\lambda$). see [HERE](https://stats.stackexchange.com/questions/138569/why-is-lambda-within-one-standard-error-from-the-minimum-is-a-recommended-valu)       
-   choice of cross-validation error measure (default for binary outcome = deviance)    

```{r, message = F}
library(glmnet)
set.seed(11)
# Cross-validation of Ridge model

ControlParameters <- trainControl(method = "cv",
                                  number = 10)

Hyperspace_param <- expand.grid(alpha = seq(0, 1, by = 0.1),
                                lambda = seq(0.001,0.1,by = 0.001))

CV.Elastic <- train(x = x_train_dm,
                    y = y_train,
                    trControl = ControlParameters,
                    tuneGrid = Hyperspace_param,
                    method = "glmnet")

# Change of cross-validation measure with log(lambda)
plot(CV.Elastic)
CV.Elastic$bestTune
```

```{r, echo = F}
Coef_Elastic <- coef(CV.Elastic$finalModel, CV.Elastic$bestTune$lambda)
Coef_Elastic

GLM <- glm(formula = DEATH_EVENT ~ .,
              data = heart_train,
              family = "binomial")
summary(GLM) 
plot(y = GLM$coefficients[-1], x = (1:11)+0.2, pch = "", axes = FALSE, xlim = c(0, 12),
     xlab = "Variable", ylab = "Coefficient", main = "Comparison of GLM (black) and Elasticnet (red) coefficients.")
rect(xleft = seq(0.5, 10.5, by = 1),
     xright = seq(1.5, 11.5, by = 1),
     ytop = -100,
     ybottom = 100,
     col = ggplot2::alpha(c("white", "bisque"), 0.3), border = F)
axis(2, c(0.5, 0, -0.5), col = NA, col.ticks = 1)
axis(1, (1:11)+0.1, col = NA,
     labels = c("Age", "Anemia", "Diabetes", "Ejection", "HBP", "Platelets", "Sodium", "Sex", "Smoking", "Log(CP)", "Log(SC)"),
     col.ticks = 1)
segments(x0 = 1:11, x1 = 1:11, y1 = Coef_Elastic[-c(1,3, 5, 8, 12, 14)], y0 = 0, lty = "dotted",)
segments(x0 = (1:11)+0.2, x1 = (1:11)+0.2, y1 = GLM$coefficients[-1], y0 = 0, lty = "dotted")
abline(h = 0)
points(y = GLM$coefficients[-1], x = (1:11)+0.2, col = "black", pch = 16, cex = 1.5)
points(y = Coef_Elastic[-c(1,3, 5, 8, 12, 14)], x = 1:11, col = "red", pch = 4, cex = 1.5, lwd = 2)
```

```{r}
# Prediction and summary statistics in training dataset
heart_train$DEATH_EVENT_pred <- predict(CV.Elastic, type = "raw", s = CV.Elastic$bestTune$lambda, alpha = CV.Elastic$bestTune$alpha)
confusionMatrix(factor(heart_train$DEATH_EVENT), factor(heart_train$DEATH_EVENT_pred))
```

***   

**(3)Predicting on testing data set**   

**Parameters to consider**    
-    Are previous steps correct ? 

```{r}
# Prediction and summary statistics in testing dataset
library(caret)
A <- predict(CV.Elastic$finalModel, newx = x_test_dm, s = CV.Elastic$bestTune$lambda, type = "class")
confusionMatrix(factor(heart_test$DEATH_EVENT), factor(A))
```

***   
  
#### Y is continuous   

**Summary of the different steps**  
**(1)**    <span style="color:#d62d20">Data management</span>    
Continuous data should be scaled    
Dummy variables must be created for categorical variables   
Training and testing data sets must be created   
  
**(2)**    <span style="color:#d62d20">Training of the data set</span>    
Find $\lambda$ and $\alpha$ which minimize cross-validation error measure (mean squared error for continuous outcomes)    
Predict on training dataset using the optimal $\lambda$ and $\alpha$ combination   
  
**(3)**    <span style="color:#d62d20">Predicting on testing data set</span>    
Predict on testing dataset       
  
***

**(1) Data management**  

**Parameters to consider**    
- Scaling methodology [LINK](https://www.google.fr).    
- Weighting of the sampling [LINK](https://www.google.fr).    

The Heart Failure Prediction data was used. The outcome was ejection fraction and predictors were all others variables except death.
More information about the dataset can be found in the dataset tab ([HERE](https://WWW.google.fr)) or on the kaggle site ([HERE](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data?select=heart_failure_clinical_records_dataset.csv)).

```{r, message = FALSE}

```

***   

**(2) Training of the data set** 

**Parameters to consider**    
-   nfolds: the number of cross-validation (default = 10).    
-   standardize: standardize the x variables (default = TRUE).    
-   $\alpha$: the mixing parameter.   
-   $\lambda$: the choice of optimal $\lambda$ to choose (minimal or in 1SE range of the minimal $\lambda$). see [HERE](https://stats.stackexchange.com/questions/138569/why-is-lambda-within-one-standard-error-from-the-minimum-is-a-recommended-valu)       
-   choice of cross-validation error measure (default for continuous outcome = mean squared error)[HERE](https://stats.stackexchange.com/questions/131267/how-to-interpret-error-measures)    

```{r, message = T}

```

```{r, echo = F}

```

***   

**(3)Predicting on testing data set**   

**Parameters to consider**    
-    Are previous steps correct ? 

```{r}

```

***   
  
#### Y is a time-to-event outcome   

**Summary of the different steps**  
**(1)**    <span style="color:#d62d20">Data management</span>    
Continuous data should be scaled    
Dummy variables must be created for categorical variables   
Training and testing data sets must be created   
  
**(2)**    <span style="color:#d62d20">Training of the data set</span>    
Find $\lambda$ and $\alpha$ which minimize cross-validation error measure (partial likelihood deviance for time-to-event outcomes)    
Predict on training dataset using the optimal $\lambda$ and $\alpha$ combination   
  
**(3)**    <span style="color:#d62d20">Predicting on testing data set</span>    
Predict on testing dataset       
  
***

**(1) Data management**  

**Parameters to consider**    
- Scaling methodology [LINK](https://www.google.fr).    
- Weighting of the sampling [LINK](https://www.google.fr).    
- Choice of time-scale for time-to-event variable.    

The Heart Failure Prediction data was used. The outcome was death as a time-to-event data and predictors were all others variables.
More information about the dataset can be found in the dataset tab ([HERE](https://benjamlandre.github.io/MLClub/dataset_page.html)) or on the kaggle site ([HERE](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data?select=heart_failure_clinical_records_dataset.csv)).

```{r, message = FALSE}

```

***   

**(2) Training of the data set** 

**Parameters to consider**    
-   nfolds: the number of cross-validation (default = 10).    
-   standardize: standardize the x variables (default = TRUE).    
-   $\alpha$: the mixing parameter.   
-   $\lambda$: the choice of optimal $\lambda$ to choose (minimal or in 1SE range of the minimal $\lambda$). see [HERE](https://stats.stackexchange.com/questions/138569/why-is-lambda-within-one-standard-error-from-the-minimum-is-a-recommended-valu)       
-   choice of cross-validation error measure (default for continuous outcome = mean squared error)[HERE](https://stats.stackexchange.com/questions/131267/how-to-interpret-error-measures)    

```{r, message = T}

```

```{r, echo = F}

```

```{r}
# Prediction and summary statistics in training dataset

```

***   

**(3)Predicting on testing data set**   

**Parameters to consider**    
-    Are previous steps correct ? 

```{r}
# Prediction and summary statistics in testing dataset

```

***  

###       
<h2>Repeated cross-validated LASSO model</h2>

Coming soon.    

***   

# References    